{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import randn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dataprep as dp\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, RANSACRegressor, Ridge, Lasso, ElasticNet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df= pd.read_csv('test.csv')\n",
    "submission= pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_train=['hour', 'hour_bef_temperature', 'hour_bef_windspeed', 'hour_bef_humidity', 'hour_bef_visibility', 'hour_bef_ozone','count']\n",
    "columns_test=['hour', 'hour_bef_temperature', 'hour_bef_windspeed', 'hour_bef_humidity', 'hour_bef_visibility', 'hour_bef_ozone']\n",
    "train=train_df[columns_train]\n",
    "test=test_df[columns_test]\n",
    "train.drop(index=[934,1035], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0e02fc9b4b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIterativeImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mit_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mit_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIterativeImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2021\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "it_train = train.copy()\n",
    "\n",
    "it_train = IterativeImputer(random_state=2021).fit_transform(it_train)\n",
    "\n",
    "itImp = pd.DataFrame(it_train)\n",
    "itImp.columns = train.columns\n",
    "\n",
    "itImp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour                    0\n",
       "hour_bef_temperature    0\n",
       "hour_bef_windspeed      0\n",
       "hour_bef_humidity       0\n",
       "hour_bef_visibility     0\n",
       "hour_bef_ozone          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_test = test.copy()\n",
    "\n",
    "it_test = IterativeImputer(random_state=2021).fit_transform(it_test)\n",
    "\n",
    "itImp1 = pd.DataFrame(it_test)\n",
    "itImp1.columns = test.columns\n",
    "\n",
    "itImp1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1433 entries, 0 to 1456\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   hour                  1433 non-null   float64\n",
      " 1   hour_bef_temperature  1433 non-null   float64\n",
      " 2   hour_bef_windspeed    1433 non-null   float64\n",
      " 3   hour_bef_humidity     1433 non-null   float64\n",
      " 4   hour_bef_visibility   1433 non-null   float64\n",
      " 5   hour_bef_ozone        1433 non-null   float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 78.4 KB\n"
     ]
    }
   ],
   "source": [
    "itImp_mid = itImp.copy()\n",
    "col_name=['hour', 'hour_bef_temperature', 'hour_bef_windspeed', 'hour_bef_humidity', 'hour_bef_visibility', 'hour_bef_ozone']\n",
    "for ilt in col_name:\n",
    "    Q1=itImp_mid[ilt].quantile(0.25)\n",
    "    Q3=itImp_mid[ilt].quantile(0.75)\n",
    "    IQR=Q3-Q1\n",
    "    train_delout=itImp_mid[(itImp_mid[ilt]<(Q1 - 1.5*IQR)) | (itImp_mid[ilt]>(Q3+1.5*IQR))]\n",
    "    itImp_mid=itImp_mid.drop(train_delout.index, axis=0)\n",
    "itImp_mid[col_name].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['hour', 'hour_bef_temperature', 'hour_bef_windspeed', 'hour_bef_humidity', 'hour_bef_ozone']\n",
    "\n",
    "X_train = itImp_mid[col]\n",
    "y_train = itImp_mid[['count']]\n",
    "X_test = itImp1[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eT_reg=ExtraTreesRegressor()\n",
    "n_estimator_param=[i for i in range(100,1000,100)]\n",
    "max_depth_param=[i for i in range(5,20)]\n",
    "min_samples_split_param=[i for i in range(2,10)]\n",
    "\n",
    "param_grid={'n_estimators' : n_estimator_param,\n",
    "             'max_depth': max_depth_param,\n",
    "            'min_samples_split': min_samples_split_param}\n",
    "\n",
    "gs= GridSearchCV(eT_reg, param_grid=param_grid, scoring='neg_mean_squared_error',cv=5,n_jobs=-1)\n",
    "gs=gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "best_reg = ExtraTreesRegressor(n_estimators=400, max_depth=10, random_state=2021)\n",
    "best_reg.fit(X_train, y_train)\n",
    "y_preds = best_reg.predict(X_test)\n",
    "\n",
    "submission['count'] = y_preds\n",
    "submission.to_csv('Extra.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
